{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKEsZgnVB-CW"
      },
      "source": [
        "# 안전 벡터맨\n",
        "\n",
        "## 건설 현장 안전 사고방지 AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLiaN92dlEUT",
        "outputId": "dae1fbf7-3621-4c7e-9c63-4bb729ab2a47"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHgrhVbLnM6I",
        "outputId": "95b529bc-eb7f-4b39-e854-59128e1c735f"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade jsonlines openai langchain langchain-openai langchain-community -q\n",
        "!pip install chromadb==0.5.3 langchain-chroma tiktoken rank_bm25 -q\n",
        "!pip install pymupdf pypdf pypdf2 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5uYZQknXLDM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"\n",
        "# 환경변수에 OPENAI_API_KEY를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kZxXmSjQRHy"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HthIQomXB-Cc",
        "outputId": "0c9bb1ad-1ade-471e-cdc5-8ee6fafefb10"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from glob import glob\n",
        "\n",
        "path = '/content/drive/MyDrive/skala/건설현장지침/*.pdf' # './drive/MyDrive/8_papers/*.pdf'\n",
        "\n",
        "glob(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i613g_qDr0Mh",
        "outputId": "23acbe22-2a40-4be5-d9df-6e8678ec9365"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import re\n",
        "from langchain_community.document_loaders import PyPDFLoader  # PyPDFLoader 추가\n",
        "from langchain.schema import Document\n",
        "\n",
        "# PDF 파일 경로 설정\n",
        "pdf_files = glob.glob('/content/drive/MyDrive/skala/건설현장지침/*.pdf')\n",
        "\n",
        "# 전처리 함수 정의\n",
        "def clean_text(text):\n",
        "    # 페이지 번호 및 특수문자 제거\n",
        "    text = re.sub(r'\\n{2,}', ' ', text)  # 연속 개행을 공백으로 변환\n",
        "    text = re.sub(r'[\\n]', ' ', text)     # 일반 개행도 공백으로 변환\n",
        "    text = re.sub(r'[^\\S\\n]+', ' ', text) # 다중 공백 제거\n",
        "    text = text.strip()  # 양끝 공백 제거\n",
        "    return text\n",
        "\n",
        "# PDF 파일 로드 및 전처리\n",
        "all_papers = []\n",
        "\n",
        "for i, path_paper in enumerate(pdf_files):\n",
        "    try:\n",
        "        loader = PyPDFLoader(path_paper)  # PyPDFLoader 사용\n",
        "        pages = loader.load()\n",
        "    except:\n",
        "        print(f\"{path_paper} 로드 실패, 스킵합니다.\")\n",
        "        continue\n",
        "\n",
        "    # PDF 페이지 병합 및 전처리\n",
        "    doc = Document(page_content='', metadata={'index': i, 'source': pages[0].metadata['source']})\n",
        "    for page in pages:\n",
        "        clean_content = clean_text(page.page_content)\n",
        "        doc.page_content += clean_content + \" \"\n",
        "\n",
        "    all_papers.append(doc)\n",
        "\n",
        "print(f\"총 {len(all_papers)}개의 문서가 로드되었습니다.\")\n",
        "print(\"샘플 문서:\", all_papers[:3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SPZPJsKXrh3",
        "outputId": "4b8e7660-cd84-4c55-ba41-42d869432f24"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "encoder = tiktoken.encoding_for_model('gpt-4o-mini') # 텍스트를 토큰으로 변환하기 위해, OpenAI 제공 패키지 tiktoken 사용\n",
        "for paper in all_papers:\n",
        "    print(len(encoder.encode(paper.page_content)), paper.metadata['source']) # 각 문서별 토큰 갯수 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwS_mNK1BYxa",
        "outputId": "fca42f8e-efc2-4f97-fe31-9b32bafa413c"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import tiktoken\n",
        "token_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    chunk_size=800, # 800 토큰 단위 (GPT-4o-mini 기준)\n",
        "    chunk_overlap=80,\n",
        ")\n",
        "\n",
        "\n",
        "token_chunks = token_splitter.split_documents(all_papers)\n",
        "print(len(token_chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7D0khLSB-Cc",
        "outputId": "7cb194ec-e809-4c99-9abe-224ec206b553"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small') # 'text-embedding-3-large'\n",
        "\n",
        "Chroma().delete_collection()\n",
        "db = Chroma.from_documents(documents=token_chunks, # 이 코드에서 Chroma.from_document()이 실행되면 embedding을 사용하여 텍스트를 벡터로 변환하고 DB에 저장함.\n",
        "                           embedding=embeddings,\n",
        "                           #persist_directory=\"./chroma_Web\", #  디스크에 저장하고 싶을 때 사용 #'./drive/MyDrive/8_papers./*.pdf'\n",
        "                           collection_metadata={'hnsw:space':'l2'} # ChromaDB는 고차원 벡터 검색을 빠르게 수행하기 위해 HNSW 알고리즘을 사용, \"hnsw:space\"는 HNSW 검색 공간 거리 계산 방식 지정 키, \"l2\"는 L2 거리(유클리드 거리, Euclidean Distance) 의미\n",
        "                           )\n",
        "# Top 5 검색하기\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 5}) # db에서 벡터 검색을 수행할 수 있도록 설정함, 데이터 저장이 완료된 이후에 retriever를 통해 검색 가능\n",
        "\n",
        "# filter 옵션을 통해 특정 메타데이터를 가진 벡터만 검색 가능\n",
        "# retriever = db.as_retriever(search_kwargs={\"k\": 5,\"filter\":{'author':'Sugnryel Lim'}})\n",
        "\n",
        "retriever.invoke('안전')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LQei0QB7yEr",
        "outputId": "ab2e3cac-9f97-4520-9652-f1f106162053"
      },
      "outputs": [],
      "source": [
        "# vector store에서 유사도 확인하기\n",
        "query = \"How does Exaone achieve good evaluation results?\"\n",
        "db.similarity_search_with_score(query) # 유사도 스코어는 0 ~ 1 사이 값을 가지며, 1에 가까울 수록 더 유사한 문서이다.\n",
        "\n",
        "# 참고로, HNSW에서 l1은 코사인 유사도로 -1 ~ 1 사이 값을 가진다. 두 벡터가 동일한 방향을 가리킬 수록 1에 가까워지며 유사도가 높음\n",
        "  # cos 0∘ = 1 → 완전히 같은 방향 (유사도가 1)\n",
        "  # cos 90∘ = 0 → 서로 직교 (연관성이 없음)\n",
        "  # cos 180∘ = −1 → 완전히 반대 방향 (유사도가 -1)\n",
        "\n",
        "# l2는 유클리드 거리 유사도로, 0에 가까울 수록 유사도가 높다. (벡터들이 더 가까움)\n",
        "  # 두 점(벡터) 사이의 직선 거리(즉, 피타고라스 정리 기반의 거리)를 측정하여 유사도를 판단하는 방식\n",
        "  # 두 벡터의 차이의 제곱합을 계산하여 루트를 씌운 값이 유클리드 거리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1-V5_Yb7yEr"
      },
      "outputs": [],
      "source": [
        "def retriever_with_score(query):\n",
        "    docs, scores = zip(*db.similarity_search_with_score(query)) # * 연산자는 리스트의 각 요소를 개별적으로 풀어서(zip 해체) 따로 추출함, 여기서는 scores만 따로 추출\n",
        "    for doc, score in zip(docs, scores):\n",
        "        doc.metadata[\"score\"] = score\n",
        "\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3QwErit7yEr",
        "outputId": "1fcd5f6f-5e6e-43b6-faf1-42eee719d7bc"
      },
      "outputs": [],
      "source": [
        "# Query 검색\n",
        "# RunnableLambda : 함수를 Runnable로 Wrap\n",
        "\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "unique_docs = RunnableLambda(\n",
        "    retriever_with_score).invoke(\"How does Exaone achieve good evaluation results?\")\n",
        "# 함수에 직접 invoke를 실행 가능하도록 RunnableLamda()로 묶음\n",
        "unique_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW6IgqNtOvVj"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKpQh1QlPW9d",
        "outputId": "451ad871-ea5c-4a6a-957b-2b25acb62451"
      },
      "outputs": [],
      "source": [
        "# 프롬프트 설정\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"user\", '''당신은 건설 현장 안전 도우미 AI입니다. 다음의 Context를 이용하여 Question에 답변하세요.\n",
        "\n",
        "### Chain-of-Thought : 안전 지침을 열고 해당 작업에 대한 준비 사항을 확인한다. 준비 사항 중 잊지 말아야 할 것을 기록한다.\n",
        "시공 순서를 탐색한다. 예를 들어 지하 연속벽의 경우 안내벽 설치부터 콘크리트 타설까지 진행된다. 공정 순서를 우선 나열한 뒤, 각 공정에 대해 주요 안전사항을 기록한다.\n",
        "안전화나 고도와 같은 기초 안전 내용보다는 압송 장치와 같이 디테일해서 놓칠 수 있는 부분을 찾아서 기록한다.\n",
        "만일 작업의 특정 공정에 대해 물어본 경우, 내용을 구체적으로 기록한다.\n",
        "\n",
        "### Condition :\n",
        "1. 공정 순서를 먼저 나열한 후, 각 공정 단계별로 소제목을 구성하고, 단계별 중요도가 높은 사항을 기준으로 작성한다.\n",
        "2. 어느 조항을 참조하는 지 작성하지 않는다.\n",
        "3. 만약 모든 Context를 다 확인해도 정보가 없다면, 웹 검색을 통해 추가 정보를 검색한다.\n",
        "4. 답변은 한국어로 작성한다.\n",
        "5. 모든 시공 절차에 대한 내용을 작성한다.\n",
        "\n",
        "### Output Example :\n",
        "공정 순서:\n",
        "1. 안내벽 설치 단계\n",
        "2. 플랜트 설치 단계\n",
        "3. 선행굴착 및 본굴착 단계\n",
        "\n",
        "1. 안내벽 설치 단계\n",
        "   a. 안내벽 설치 전, 지반 붕괴 위험이 있으면 흙막이지보공을 설치한다.\n",
        "   b. 야간작업 시 충분한 조명(75럭스 이상)과 형광벨트, 경광등을 설치한다.\n",
        "   c. 굴착장비가 사면에 지나치게 근접해 붕괴되지 않도록 한다.\n",
        "\n",
        "2. 플랜트 설치 단계\n",
        "   a. 구동벨트는 철망으로 감싸 끼임 사고를 방지한다.\n",
        "   b. 사일로 점검을 위한 사다리 및 난간을 반드시 설치한다.\n",
        "   c. 배관 연결 상태를 점검하고, 펌프 압력으로 유동되지 않도록 고정한다.\n",
        "\n",
        "3. 선행굴착 및 본굴착 단계\n",
        "   a. 트렌치 커터 이동 시 지반침하 방지를 위해 콘크리트를 타설하거나 철판을 깐다.\n",
        "   b. 크레인 작업 구역에 근로자가 접근하지 않도록 통제한다.\n",
        "   c. 굴착 중 지하 매설물(가스관, 상수도관 등) 위치를 사전에 확인하고 보호 조치를 취한다.\n",
        "---\n",
        "Context: {context}\n",
        "---\n",
        "Question: {question}''')\n",
        "])\n",
        "\n",
        "prompt.pretty_print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrJD53z-POIa"
      },
      "outputs": [],
      "source": [
        "translate_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('system', '주어진 질문을 영어로 변환하세요.'),\n",
        "        ('user', 'Question: {question}')\n",
        "    ]\n",
        ")\n",
        "translate_chain = translate_prompt | llm | StrOutputParser()\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n---\\n\".join([doc.page_content+ '\\nURL: '+ doc.metadata['source'] for doc in docs])\n",
        "    # join : 구분자를 기준으로 스트링 리스트를 하나의 스트링으로 연결\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": translate_chain | retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    # context는 질문을 번역하고 검색한 문서를 텍스트로 변환한 것이며, question은 원래 질문을 그대로 유지\n",
        "    # retriever : question을 받아서 context 검색: document 반환, format_docs : document 형태를 받아서 텍스트로 변환\n",
        "    # RunnablePassthrough(): 체인의 입력을 그대로 저장\n",
        "    | prompt\n",
        "    # context (검색된 문서)와 question (질문)을 이용하여 LLM에게 입력할 최종 프롬프트를 생성\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_veMYqZ7yEs",
        "outputId": "b6e01712-5acd-4d23-c238-dff5d581a1e4"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    '오늘  SCW 공법을 사용해서 흙막이 공사 할건데 안전 수칙 알려줘'\n",
        "]\n",
        "result = rag_chain.batch(questions)\n",
        "for i, ans in enumerate(result):\n",
        "    ans = ans.replace('.','.\\n')\n",
        "    print(f\"Question: {questions[i]}\")\n",
        "    print(f\"Answer: {ans}\")\n",
        "    print('---')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmi7mQ63_Bwn",
        "outputId": "087a04cd-0717-4e32-b368-76be4d9c4952"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "WD89v3eW-cs1",
        "outputId": "f5ddaa62-c76d-462f-c431-75140f061c33"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import asyncio\n",
        "\n",
        "def analyze_excavation_safety(question):\n",
        "    \"\"\"\n",
        "    질문을 받아 RAG 모델을 호출하여 안전 정보를 제공하는 함수\n",
        "    \"\"\"\n",
        "    result = rag_chain.invoke(question)  # RAG 체인을 활용한 응답 생성\n",
        "    formatted_result = result.replace('.', '.\\n')  # 가독성 향상\n",
        "    return formatted_result\n",
        "\n",
        "# ✅ Gradio UI 구성\n",
        "with gr.Blocks(css=\".gradio-container {max-width: 800px; margin: auto; font-family: 'Arial', sans-serif;}\") as demo:\n",
        "    gr.Markdown(\"## 🏗️ 건설현장 안전사고 방지 AI\")\n",
        "    gr.Markdown(\"건설현장에서 발생할 수 있는 사고에 대해 질문하면, 벡터 DB와 RAG 기술을 활용한 학습 데이터 기반의 정보를 제공합니다.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            question_input = gr.Textbox(\n",
        "                label=\"💬 건설현장 관련 사고 질문 입력\",\n",
        "                placeholder=\"예: 오늘 SCW 공법을 사용할 건데 안전 수칙 알려줘\",\n",
        "                lines=2,\n",
        "                interactive=True\n",
        "            )\n",
        "            submit_button = gr.Button(\"🚀 분석 실행\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_box = gr.Textbox(\n",
        "                label=\"📝 분석 결과\",\n",
        "                placeholder=\"AI가 분석한 결과가 여기에 표시됩니다.\",\n",
        "                lines=10,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "    submit_button.click(fn=analyze_excavation_safety, inputs=[question_input], outputs=output_box)\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"&copy; 2025 안전 벡터맨 All rights reserved\")\n",
        "\n",
        "# 실행\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
