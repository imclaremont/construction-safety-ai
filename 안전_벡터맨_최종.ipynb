{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKEsZgnVB-CW"
      },
      "source": [
        "# ì•ˆì „ ë²¡í„°ë§¨\n",
        "\n",
        "## ê±´ì„¤ í˜„ì¥ ì•ˆì „ ì‚¬ê³ ë°©ì§€ AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLiaN92dlEUT",
        "outputId": "dae1fbf7-3621-4c7e-9c63-4bb729ab2a47"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHgrhVbLnM6I",
        "outputId": "95b529bc-eb7f-4b39-e854-59128e1c735f"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade jsonlines openai langchain langchain-openai langchain-community -q\n",
        "!pip install chromadb==0.5.3 langchain-chroma tiktoken rank_bm25 -q\n",
        "!pip install pymupdf pypdf pypdf2 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5uYZQknXLDM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"\n",
        "# í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kZxXmSjQRHy"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HthIQomXB-Cc",
        "outputId": "0c9bb1ad-1ade-471e-cdc5-8ee6fafefb10"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from glob import glob\n",
        "\n",
        "path = '/content/drive/MyDrive/skala/á„€á…¥á†«á„‰á…¥á†¯á„’á…§á†«á„Œá…¡á†¼á„Œá…µá„á…µá†·/*.pdf' # './drive/MyDrive/8_papers/*.pdf'\n",
        "\n",
        "glob(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i613g_qDr0Mh",
        "outputId": "23acbe22-2a40-4be5-d9df-6e8678ec9365"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import re\n",
        "from langchain_community.document_loaders import PyPDFLoader  # PyPDFLoader ì¶”ê°€\n",
        "from langchain.schema import Document\n",
        "\n",
        "# PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "pdf_files = glob.glob('/content/drive/MyDrive/skala/á„€á…¥á†«á„‰á…¥á†¯á„’á…§á†«á„Œá…¡á†¼á„Œá…µá„á…µá†·/*.pdf')\n",
        "\n",
        "# ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
        "def clean_text(text):\n",
        "    # í˜ì´ì§€ ë²ˆí˜¸ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "    text = re.sub(r'\\n{2,}', ' ', text)  # ì—°ì† ê°œí–‰ì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜\n",
        "    text = re.sub(r'[\\n]', ' ', text)     # ì¼ë°˜ ê°œí–‰ë„ ê³µë°±ìœ¼ë¡œ ë³€í™˜\n",
        "    text = re.sub(r'[^\\S\\n]+', ' ', text) # ë‹¤ì¤‘ ê³µë°± ì œê±°\n",
        "    text = text.strip()  # ì–‘ë ê³µë°± ì œê±°\n",
        "    return text\n",
        "\n",
        "# PDF íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "all_papers = []\n",
        "\n",
        "for i, path_paper in enumerate(pdf_files):\n",
        "    try:\n",
        "        loader = PyPDFLoader(path_paper)  # PyPDFLoader ì‚¬ìš©\n",
        "        pages = loader.load()\n",
        "    except:\n",
        "        print(f\"{path_paper} ë¡œë“œ ì‹¤íŒ¨, ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
        "        continue\n",
        "\n",
        "    # PDF í˜ì´ì§€ ë³‘í•© ë° ì „ì²˜ë¦¬\n",
        "    doc = Document(page_content='', metadata={'index': i, 'source': pages[0].metadata['source']})\n",
        "    for page in pages:\n",
        "        clean_content = clean_text(page.page_content)\n",
        "        doc.page_content += clean_content + \" \"\n",
        "\n",
        "    all_papers.append(doc)\n",
        "\n",
        "print(f\"ì´ {len(all_papers)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"ìƒ˜í”Œ ë¬¸ì„œ:\", all_papers[:3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SPZPJsKXrh3",
        "outputId": "4b8e7660-cd84-4c55-ba41-42d869432f24"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "encoder = tiktoken.encoding_for_model('gpt-4o-mini') # í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´, OpenAI ì œê³µ íŒ¨í‚¤ì§€ tiktoken ì‚¬ìš©\n",
        "for paper in all_papers:\n",
        "    print(len(encoder.encode(paper.page_content)), paper.metadata['source']) # ê° ë¬¸ì„œë³„ í† í° ê°¯ìˆ˜ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwS_mNK1BYxa",
        "outputId": "fca42f8e-efc2-4f97-fe31-9b32bafa413c"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import tiktoken\n",
        "token_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    chunk_size=800, # 800 í† í° ë‹¨ìœ„ (GPT-4o-mini ê¸°ì¤€)\n",
        "    chunk_overlap=80,\n",
        ")\n",
        "\n",
        "\n",
        "token_chunks = token_splitter.split_documents(all_papers)\n",
        "print(len(token_chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7D0khLSB-Cc",
        "outputId": "7cb194ec-e809-4c99-9abe-224ec206b553"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small') # 'text-embedding-3-large'\n",
        "\n",
        "Chroma().delete_collection()\n",
        "db = Chroma.from_documents(documents=token_chunks, # ì´ ì½”ë“œì—ì„œ Chroma.from_document()ì´ ì‹¤í–‰ë˜ë©´ embeddingì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  DBì— ì €ì¥í•¨.\n",
        "                           embedding=embeddings,\n",
        "                           #persist_directory=\"./chroma_Web\", #  ë””ìŠ¤í¬ì— ì €ì¥í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš© #'./drive/MyDrive/8_papers./*.pdf'\n",
        "                           collection_metadata={'hnsw:space':'l2'} # ChromaDBëŠ” ê³ ì°¨ì› ë²¡í„° ê²€ìƒ‰ì„ ë¹ ë¥´ê²Œ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ HNSW ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©, \"hnsw:space\"ëŠ” HNSW ê²€ìƒ‰ ê³µê°„ ê±°ë¦¬ ê³„ì‚° ë°©ì‹ ì§€ì • í‚¤, \"l2\"ëŠ” L2 ê±°ë¦¬(ìœ í´ë¦¬ë“œ ê±°ë¦¬, Euclidean Distance) ì˜ë¯¸\n",
        "                           )\n",
        "# Top 5 ê²€ìƒ‰í•˜ê¸°\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 5}) # dbì—ì„œ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•¨, ë°ì´í„° ì €ì¥ì´ ì™„ë£Œëœ ì´í›„ì— retrieverë¥¼ í†µí•´ ê²€ìƒ‰ ê°€ëŠ¥\n",
        "\n",
        "# filter ì˜µì…˜ì„ í†µí•´ íŠ¹ì • ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì§„ ë²¡í„°ë§Œ ê²€ìƒ‰ ê°€ëŠ¥\n",
        "# retriever = db.as_retriever(search_kwargs={\"k\": 5,\"filter\":{'author':'Sugnryel Lim'}})\n",
        "\n",
        "retriever.invoke('ì•ˆì „')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LQei0QB7yEr",
        "outputId": "ab2e3cac-9f97-4520-9652-f1f106162053"
      },
      "outputs": [],
      "source": [
        "# vector storeì—ì„œ ìœ ì‚¬ë„ í™•ì¸í•˜ê¸°\n",
        "query = \"How does Exaone achieve good evaluation results?\"\n",
        "db.similarity_search_with_score(query) # ìœ ì‚¬ë„ ìŠ¤ì½”ì–´ëŠ” 0 ~ 1 ì‚¬ì´ ê°’ì„ ê°€ì§€ë©°, 1ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ë” ìœ ì‚¬í•œ ë¬¸ì„œì´ë‹¤.\n",
        "\n",
        "# ì°¸ê³ ë¡œ, HNSWì—ì„œ l1ì€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ -1 ~ 1 ì‚¬ì´ ê°’ì„ ê°€ì§„ë‹¤. ë‘ ë²¡í„°ê°€ ë™ì¼í•œ ë°©í–¥ì„ ê°€ë¦¬í‚¬ ìˆ˜ë¡ 1ì— ê°€ê¹Œì›Œì§€ë©° ìœ ì‚¬ë„ê°€ ë†’ìŒ\n",
        "  # cos 0âˆ˜ = 1 â†’ ì™„ì „íˆ ê°™ì€ ë°©í–¥ (ìœ ì‚¬ë„ê°€ 1)\n",
        "  # cos 90âˆ˜ = 0 â†’ ì„œë¡œ ì§êµ (ì—°ê´€ì„±ì´ ì—†ìŒ)\n",
        "  # cos 180âˆ˜ = âˆ’1 â†’ ì™„ì „íˆ ë°˜ëŒ€ ë°©í–¥ (ìœ ì‚¬ë„ê°€ -1)\n",
        "\n",
        "# l2ëŠ” ìœ í´ë¦¬ë“œ ê±°ë¦¬ ìœ ì‚¬ë„ë¡œ, 0ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ë‹¤. (ë²¡í„°ë“¤ì´ ë” ê°€ê¹Œì›€)\n",
        "  # ë‘ ì (ë²¡í„°) ì‚¬ì´ì˜ ì§ì„  ê±°ë¦¬(ì¦‰, í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ ê¸°ë°˜ì˜ ê±°ë¦¬)ë¥¼ ì¸¡ì •í•˜ì—¬ ìœ ì‚¬ë„ë¥¼ íŒë‹¨í•˜ëŠ” ë°©ì‹\n",
        "  # ë‘ ë²¡í„°ì˜ ì°¨ì´ì˜ ì œê³±í•©ì„ ê³„ì‚°í•˜ì—¬ ë£¨íŠ¸ë¥¼ ì”Œìš´ ê°’ì´ ìœ í´ë¦¬ë“œ ê±°ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1-V5_Yb7yEr"
      },
      "outputs": [],
      "source": [
        "def retriever_with_score(query):\n",
        "    docs, scores = zip(*db.similarity_search_with_score(query)) # * ì—°ì‚°ìëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ê° ìš”ì†Œë¥¼ ê°œë³„ì ìœ¼ë¡œ í’€ì–´ì„œ(zip í•´ì²´) ë”°ë¡œ ì¶”ì¶œí•¨, ì—¬ê¸°ì„œëŠ” scoresë§Œ ë”°ë¡œ ì¶”ì¶œ\n",
        "    for doc, score in zip(docs, scores):\n",
        "        doc.metadata[\"score\"] = score\n",
        "\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3QwErit7yEr",
        "outputId": "1fcd5f6f-5e6e-43b6-faf1-42eee719d7bc"
      },
      "outputs": [],
      "source": [
        "# Query ê²€ìƒ‰\n",
        "# RunnableLambda : í•¨ìˆ˜ë¥¼ Runnableë¡œ Wrap\n",
        "\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "unique_docs = RunnableLambda(\n",
        "    retriever_with_score).invoke(\"How does Exaone achieve good evaluation results?\")\n",
        "# í•¨ìˆ˜ì— ì§ì ‘ invokeë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ RunnableLamda()ë¡œ ë¬¶ìŒ\n",
        "unique_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW6IgqNtOvVj"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKpQh1QlPW9d",
        "outputId": "451ad871-ea5c-4a6a-957b-2b25acb62451"
      },
      "outputs": [],
      "source": [
        "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"user\", '''ë‹¹ì‹ ì€ ê±´ì„¤ í˜„ì¥ ì•ˆì „ ë„ìš°ë¯¸ AIì…ë‹ˆë‹¤. ë‹¤ìŒì˜ Contextë¥¼ ì´ìš©í•˜ì—¬ Questionì— ë‹µë³€í•˜ì„¸ìš”.\n",
        "\n",
        "### Chain-of-Thought : ì•ˆì „ ì§€ì¹¨ì„ ì—´ê³  í•´ë‹¹ ì‘ì—…ì— ëŒ€í•œ ì¤€ë¹„ ì‚¬í•­ì„ í™•ì¸í•œë‹¤. ì¤€ë¹„ ì‚¬í•­ ì¤‘ ìŠì§€ ë§ì•„ì•¼ í•  ê²ƒì„ ê¸°ë¡í•œë‹¤.\n",
        "ì‹œê³µ ìˆœì„œë¥¼ íƒìƒ‰í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì§€í•˜ ì—°ì†ë²½ì˜ ê²½ìš° ì•ˆë‚´ë²½ ì„¤ì¹˜ë¶€í„° ì½˜í¬ë¦¬íŠ¸ íƒ€ì„¤ê¹Œì§€ ì§„í–‰ëœë‹¤. ê³µì • ìˆœì„œë¥¼ ìš°ì„  ë‚˜ì—´í•œ ë’¤, ê° ê³µì •ì— ëŒ€í•´ ì£¼ìš” ì•ˆì „ì‚¬í•­ì„ ê¸°ë¡í•œë‹¤.\n",
        "ì•ˆì „í™”ë‚˜ ê³ ë„ì™€ ê°™ì€ ê¸°ì´ˆ ì•ˆì „ ë‚´ìš©ë³´ë‹¤ëŠ” ì••ì†¡ ì¥ì¹˜ì™€ ê°™ì´ ë””í…Œì¼í•´ì„œ ë†“ì¹  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ì°¾ì•„ì„œ ê¸°ë¡í•œë‹¤.\n",
        "ë§Œì¼ ì‘ì—…ì˜ íŠ¹ì • ê³µì •ì— ëŒ€í•´ ë¬¼ì–´ë³¸ ê²½ìš°, ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ë¡í•œë‹¤.\n",
        "\n",
        "### Condition :\n",
        "1. ê³µì • ìˆœì„œë¥¼ ë¨¼ì € ë‚˜ì—´í•œ í›„, ê° ê³µì • ë‹¨ê³„ë³„ë¡œ ì†Œì œëª©ì„ êµ¬ì„±í•˜ê³ , ë‹¨ê³„ë³„ ì¤‘ìš”ë„ê°€ ë†’ì€ ì‚¬í•­ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•œë‹¤.\n",
        "2. ì–´ëŠ ì¡°í•­ì„ ì°¸ì¡°í•˜ëŠ” ì§€ ì‘ì„±í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
        "3. ë§Œì•½ ëª¨ë“  Contextë¥¼ ë‹¤ í™•ì¸í•´ë„ ì •ë³´ê°€ ì—†ë‹¤ë©´, ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì¶”ê°€ ì •ë³´ë¥¼ ê²€ìƒ‰í•œë‹¤.\n",
        "4. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.\n",
        "5. ëª¨ë“  ì‹œê³µ ì ˆì°¨ì— ëŒ€í•œ ë‚´ìš©ì„ ì‘ì„±í•œë‹¤.\n",
        "\n",
        "### Output Example :\n",
        "ê³µì • ìˆœì„œ:\n",
        "1. ì•ˆë‚´ë²½ ì„¤ì¹˜ ë‹¨ê³„\n",
        "2. í”ŒëœíŠ¸ ì„¤ì¹˜ ë‹¨ê³„\n",
        "3. ì„ í–‰êµ´ì°© ë° ë³¸êµ´ì°© ë‹¨ê³„\n",
        "\n",
        "1. ì•ˆë‚´ë²½ ì„¤ì¹˜ ë‹¨ê³„\n",
        "   a. ì•ˆë‚´ë²½ ì„¤ì¹˜ ì „, ì§€ë°˜ ë¶•ê´´ ìœ„í—˜ì´ ìˆìœ¼ë©´ í™ë§‰ì´ì§€ë³´ê³µì„ ì„¤ì¹˜í•œë‹¤.\n",
        "   b. ì•¼ê°„ì‘ì—… ì‹œ ì¶©ë¶„í•œ ì¡°ëª…(75ëŸ­ìŠ¤ ì´ìƒ)ê³¼ í˜•ê´‘ë²¨íŠ¸, ê²½ê´‘ë“±ì„ ì„¤ì¹˜í•œë‹¤.\n",
        "   c. êµ´ì°©ì¥ë¹„ê°€ ì‚¬ë©´ì— ì§€ë‚˜ì¹˜ê²Œ ê·¼ì ‘í•´ ë¶•ê´´ë˜ì§€ ì•Šë„ë¡ í•œë‹¤.\n",
        "\n",
        "2. í”ŒëœíŠ¸ ì„¤ì¹˜ ë‹¨ê³„\n",
        "   a. êµ¬ë™ë²¨íŠ¸ëŠ” ì² ë§ìœ¼ë¡œ ê°ì‹¸ ë¼ì„ ì‚¬ê³ ë¥¼ ë°©ì§€í•œë‹¤.\n",
        "   b. ì‚¬ì¼ë¡œ ì ê²€ì„ ìœ„í•œ ì‚¬ë‹¤ë¦¬ ë° ë‚œê°„ì„ ë°˜ë“œì‹œ ì„¤ì¹˜í•œë‹¤.\n",
        "   c. ë°°ê´€ ì—°ê²° ìƒíƒœë¥¼ ì ê²€í•˜ê³ , íŒí”„ ì••ë ¥ìœ¼ë¡œ ìœ ë™ë˜ì§€ ì•Šë„ë¡ ê³ ì •í•œë‹¤.\n",
        "\n",
        "3. ì„ í–‰êµ´ì°© ë° ë³¸êµ´ì°© ë‹¨ê³„\n",
        "   a. íŠ¸ë Œì¹˜ ì»¤í„° ì´ë™ ì‹œ ì§€ë°˜ì¹¨í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì½˜í¬ë¦¬íŠ¸ë¥¼ íƒ€ì„¤í•˜ê±°ë‚˜ ì² íŒì„ ê¹ë‹¤.\n",
        "   b. í¬ë ˆì¸ ì‘ì—… êµ¬ì—­ì— ê·¼ë¡œìê°€ ì ‘ê·¼í•˜ì§€ ì•Šë„ë¡ í†µì œí•œë‹¤.\n",
        "   c. êµ´ì°© ì¤‘ ì§€í•˜ ë§¤ì„¤ë¬¼(ê°€ìŠ¤ê´€, ìƒìˆ˜ë„ê´€ ë“±) ìœ„ì¹˜ë¥¼ ì‚¬ì „ì— í™•ì¸í•˜ê³  ë³´í˜¸ ì¡°ì¹˜ë¥¼ ì·¨í•œë‹¤.\n",
        "---\n",
        "Context: {context}\n",
        "---\n",
        "Question: {question}''')\n",
        "])\n",
        "\n",
        "prompt.pretty_print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrJD53z-POIa"
      },
      "outputs": [],
      "source": [
        "translate_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('system', 'ì£¼ì–´ì§„ ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë³€í™˜í•˜ì„¸ìš”.'),\n",
        "        ('user', 'Question: {question}')\n",
        "    ]\n",
        ")\n",
        "translate_chain = translate_prompt | llm | StrOutputParser()\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n---\\n\".join([doc.page_content+ '\\nURL: '+ doc.metadata['source'] for doc in docs])\n",
        "    # join : êµ¬ë¶„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìŠ¤íŠ¸ë§ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ìŠ¤íŠ¸ë§ìœ¼ë¡œ ì—°ê²°\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": translate_chain | retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    # contextëŠ” ì§ˆë¬¸ì„ ë²ˆì—­í•˜ê³  ê²€ìƒ‰í•œ ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œ ê²ƒì´ë©°, questionì€ ì›ë˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
        "    # retriever : questionì„ ë°›ì•„ì„œ context ê²€ìƒ‰: document ë°˜í™˜, format_docs : document í˜•íƒœë¥¼ ë°›ì•„ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
        "    # RunnablePassthrough(): ì²´ì¸ì˜ ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ì €ì¥\n",
        "    | prompt\n",
        "    # context (ê²€ìƒ‰ëœ ë¬¸ì„œ)ì™€ question (ì§ˆë¬¸)ì„ ì´ìš©í•˜ì—¬ LLMì—ê²Œ ì…ë ¥í•  ìµœì¢… í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_veMYqZ7yEs",
        "outputId": "b6e01712-5acd-4d23-c238-dff5d581a1e4"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    'ì˜¤ëŠ˜  SCW ê³µë²•ì„ ì‚¬ìš©í•´ì„œ í™ë§‰ì´ ê³µì‚¬ í• ê±´ë° ì•ˆì „ ìˆ˜ì¹™ ì•Œë ¤ì¤˜'\n",
        "]\n",
        "result = rag_chain.batch(questions)\n",
        "for i, ans in enumerate(result):\n",
        "    ans = ans.replace('.','.\\n')\n",
        "    print(f\"Question: {questions[i]}\")\n",
        "    print(f\"Answer: {ans}\")\n",
        "    print('---')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmi7mQ63_Bwn",
        "outputId": "087a04cd-0717-4e32-b368-76be4d9c4952"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "WD89v3eW-cs1",
        "outputId": "f5ddaa62-c76d-462f-c431-75140f061c33"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import asyncio\n",
        "\n",
        "def analyze_excavation_safety(question):\n",
        "    \"\"\"\n",
        "    ì§ˆë¬¸ì„ ë°›ì•„ RAG ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ì•ˆì „ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    result = rag_chain.invoke(question)  # RAG ì²´ì¸ì„ í™œìš©í•œ ì‘ë‹µ ìƒì„±\n",
        "    formatted_result = result.replace('.', '.\\n')  # ê°€ë…ì„± í–¥ìƒ\n",
        "    return formatted_result\n",
        "\n",
        "# âœ… Gradio UI êµ¬ì„±\n",
        "with gr.Blocks(css=\".gradio-container {max-width: 800px; margin: auto; font-family: 'Arial', sans-serif;}\") as demo:\n",
        "    gr.Markdown(\"## ğŸ—ï¸ ê±´ì„¤í˜„ì¥ ì•ˆì „ì‚¬ê³  ë°©ì§€ AI\")\n",
        "    gr.Markdown(\"ê±´ì„¤í˜„ì¥ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì‚¬ê³ ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´, ë²¡í„° DBì™€ RAG ê¸°ìˆ ì„ í™œìš©í•œ í•™ìŠµ ë°ì´í„° ê¸°ë°˜ì˜ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            question_input = gr.Textbox(\n",
        "                label=\"ğŸ’¬ ê±´ì„¤í˜„ì¥ ê´€ë ¨ ì‚¬ê³  ì§ˆë¬¸ ì…ë ¥\",\n",
        "                placeholder=\"ì˜ˆ: ì˜¤ëŠ˜ SCW ê³µë²•ì„ ì‚¬ìš©í•  ê±´ë° ì•ˆì „ ìˆ˜ì¹™ ì•Œë ¤ì¤˜\",\n",
        "                lines=2,\n",
        "                interactive=True\n",
        "            )\n",
        "            submit_button = gr.Button(\"ğŸš€ ë¶„ì„ ì‹¤í–‰\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_box = gr.Textbox(\n",
        "                label=\"ğŸ“ ë¶„ì„ ê²°ê³¼\",\n",
        "                placeholder=\"AIê°€ ë¶„ì„í•œ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.\",\n",
        "                lines=10,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "    submit_button.click(fn=analyze_excavation_safety, inputs=[question_input], outputs=output_box)\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"&copy; 2025 ì•ˆì „ ë²¡í„°ë§¨ All rights reserved\")\n",
        "\n",
        "# ì‹¤í–‰\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
